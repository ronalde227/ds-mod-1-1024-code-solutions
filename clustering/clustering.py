# -*- coding: utf-8 -*-
"""clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fmLZbWq_eFiXDAF0jbhS3J3pxgUxriq6
"""

import pandas as pd

#reading data from imports-85.names

with open('/content/imports-85.names') as f:
  lines = f.readlines()

attributes = []
section = False

for line in lines:
    # Check for the start of the section
    if line.strip().startswith("7. Attribute Information:"):
        section = True
        continue
    # Stop capturing when the next section starts
    if line.strip().startswith("8. M"):
        break
    # Capture attribute lines
    if section and line.strip() and line.strip()[0].isdigit():  # Lines starting with numbers
        attribute_name = line.split(":")[0].split(".")[1].strip()
        attributes.append(attribute_name)
attributes

#MAKING ATTRIBUTES THE COLUMN HEADER OF DATA

data = pd.read_csv('/content/imports-85.data', names=attributes)

data.info()

import numpy as np
import matplotlib.pyplot as plt

data.info()

data

plt.scatter(data=data, x='price', y='horsepower')

#replace ? with null
data.replace('?', np.nan, inplace=True)

#deleting all rows with null values
data.dropna(inplace=True)

data

plt.scatter(data=data, x='price', y='horsepower')

data.info()

#using simple imputer to fill in nulls with means for numerics and modes for objects
from sklearn.impute import SimpleImputer
s_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
s_imputer.fit(data[['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm','price']])
data[['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm','price']] = s_imputer.transform(data[['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm','price']])
s_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')

s_imputer.fit(data[['num-of-doors']])
data[['num-of-doors']] = s_imputer.transform(data[['num-of-doors']])

#check for nulls in data
data.isnull().sum()

plt.scatter(data=data, x='price', y='horsepower')

data[['price', 'horsepower']].corr()

x = data[['price', 'horsepower']]

#scaling x
from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
x_scaled = mms.fit_transform(x)

x_scaled

from sklearn.cluster import KMeans

from sklearn.metrics import silhouette_score, calinski_harabasz_score

inertias = []
s_scores = []
c_scores = []

for k in range(2,11):
  km = KMeans(n_clusters=k, n_init=20)
  km.fit(x_scaled)
  inertias.append(km.inertia_)
  score = silhouette_score(x_scaled, km.labels_)
  s_scores.append(score)
  score = calinski_harabasz_score(x_scaled, km.labels_)
  c_scores.append(score)

inertias

s_scores

c_scores

plt.plot(range(2,11), inertias)

#base if the elbow test - k = 5 would be a potential optimal k

plt.plot(range(2,11), s_scores)

#for the silhouette score k=2 would be optimal since k=2 yeild a value closest to 1

plt.plot(range(2,11), c_scores)

#based off the calinski test the higher values are desired so k=7 would be optimal.

#2. Plotting cluster with centroid with k=5
km = KMeans(n_clusters=2)
km.fit(x_scaled)

x = x_scaled

x

data[['price','horsepower']]

plt.scatter(x=x_scaled[:,0], y=x_scaled[:,1], c=km.labels_)
plt.scatter(x=km.cluster_centers_[:,0], y=km.cluster_centers_[:,1], marker='x', s=100, c='red')

from sklearn.cluster import DBSCAN

dbs = DBSCAN(eps=0.17, min_samples=5)
dbs.fit(x_scaled)

plt.scatter(x_scaled[:,0], x_scaled[:,1], c=dbs.labels_)

from sklearn.neighbors import NearestNeighbors

#!pip install category_encoders

mlb_df = pd.read_csv('/content/mlb_batting_cleaned.csv')

mlb_df[['Name', 'Tm', 'Lg']]



mlb_df.info()

mlb_df_nums = mlb_df.drop(columns=['Name', 'Tm', 'Lg'])

#scaler = MinMaxScaler()
#mlb_df_nums = scaler.fit_transform(mlb_df_nums)

from sklearn.preprocessing import StandardScaler


scaler = StandardScaler()
mlb_df_nums = scaler.fit_transform(mlb_df_nums)

nn = NearestNeighbors(n_neighbors=3)
nn.fit(mlb_df_nums)

dist, neighbors = nn.kneighbors(mlb_df_nums)

neighbors[524][1]

#3. Using mlb_batting_cleaned.csv, write a function that takes a player's name and shows the 2 closest players using the nearest neighbors algorithm.

def closest_players(player_name):
  player_index = mlb_df[mlb_df['Name'] == player_name].index[0]
  neighbor1 = neighbors[player_index][1]
  neighbor2 = neighbors[player_index][2]
  neighbor1_name = mlb_df.iloc[neighbor1]['Name']
  neighbor2_name = mlb_df.iloc[neighbor2]['Name']

  print(f"Input player name: {player_name}")
  print(f"the first closest player: {neighbor1_name}")
  print(f"the second closest player: {neighbor2_name}")

closest_players('Shohei Ohtani')

