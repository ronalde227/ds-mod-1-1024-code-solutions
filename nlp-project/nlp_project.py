# -*- coding: utf-8 -*-
"""nlp-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KPSaI5QkCVXAGg-JTSFcB-P0XflZ3ZZ6
"""

import pandas as pd

!pip install nltk

import nltk

nltk.download('gutenberg')

data = pd.read_csv('/content/spam.csv', encoding='latin-1')

data

#1. Preprocess the text messages
from nltk.tokenize import word_tokenize

nltk.download('punkt')

nltk.download('punkt_tab')

from nltk.stem import WordNetLemmatizer

nltk.download('wordnet')
wnl = WordNetLemmatizer()

nltk.download('stopwords')

nltk.download('averaged_perceptron_tagger_eng')

stop_words = nltk.corpus.stopwords.words('english')

stop_words.extend(['[', ']', '(', ')', '{', '}', '.', ',', '"', '!', '?', ':', ';','\''])



from nltk.corpus import wordnet

def get_wordnet_pos(treebank_tag):

    if treebank_tag.startswith('J'):
        return wordnet.ADJ
    elif treebank_tag.startswith('V'):
        return wordnet.VERB
    elif treebank_tag.startswith('N'):
        return wordnet.NOUN
    elif treebank_tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

def clean_data(text):
  tokens = word_tokenize(text)
  token_pos = nltk.pos_tag(tokens)
  tokens_lem = [wnl.lemmatize(token, get_wordnet_pos(pos)) for token, pos in
  token_pos]
  tokens_nosw = [token for token in tokens_lem if token.lower() not in stop_words]

  return " ".join(tokens_nosw)

data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)

data['v1'].value_counts()

data["is_spam"] = data["v1"].apply(lambda x: 1 if x == "spam" else 0)

data

#cleaning text field v2
data['cleaned_text'] = data['v2'].apply(clean_data)

data[['v2','cleaned_text']]

#2. Vectorize the preprocessed text messages
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')
tfidf.fit(data['cleaned_text'])

tfidf.vocabulary_

x_tfidf = tfidf.transform(data['cleaned_text'])

x_tfidf_dense = x_tfidf.toarray()
feature_names = tfidf.get_feature_names_out()

tfidf_df = pd.DataFrame(x_tfidf_dense, columns=feature_names)

tfidf_df = pd.DataFrame(x_tfidf_dense, columns=feature_names)

tfidf_df

X = tfidf_df
y = data['is_spam']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, ConfusionMatrixDisplay

#3. Build the two models of your choosing for classifying the text as spam vs. not spam.

#Model RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)

train_preds = rf_model.predict(X_train)
test_preds = rf_model.predict(X_test)

#4. Validate your models and state which performs best, considering bias and variance.

#The two models i build were for Random Forest and logistic Regression.
#Random Forest performed better than logistic regression.
#Random Forest prediction on the training data perfectly predicted out target which indicates low bias.
#The random forest model on the test data resulted in lower positive recall meaning the model predicted a few spam messages and real messages.
#Given the fact that it is better to receive a few spam messages than potentially accidentally marking a real messages as a spam message, this decrease in recall score is acceptable.

print("Train Scores for Random Forest:")
print(classification_report(y_train, train_preds))

print("Test Scores for Random: Forest")
print(classification_report(y_test, test_preds))

#now doing a logistic regression model to compare results

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train, y_train)

lr

lr_train_preds = lr.predict(X_train)
lr_test_preds = lr.predict(X_test)

#the logistic regression score recall on both the test and train lower.
#compared to training data set.
#the logistic model performed better on training set than test set.
print("Train Scores for Logistic Regression:")
print(classification_report(y_train, lr_train_preds))

print("Test Scores for Logistic Regression:")
print(classification_report(y_test, lr_test_preds))

